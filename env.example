# CTI Scraper Environment Configuration
# Copy this file to .env and modify the values

# Database Configuration
DATABASE_URL=postgresql+asyncpg://username:password@localhost:5432/dbname
POSTGRES_DB=cti_scraper
POSTGRES_USER=cti_user
POSTGRES_PASSWORD=your_secure_password_here
POSTGRES_HOST=localhost
POSTGRES_PORT=5432

# Redis Configuration
REDIS_URL=redis://:password@localhost:6379/0
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password_here
REDIS_DB=0

# Application Configuration
ENVIRONMENT=development
LOG_LEVEL=INFO
DEBUG=true
SECRET_KEY=your-super-secret-key-change-this-in-production
ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0

# Web Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=4
RELOAD=true

# Security Configuration
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]
TRUSTED_HOSTS=["localhost", "127.0.0.1", "0.0.0.0"]

# Rate Limiting
RATE_LIMIT_PER_MINUTE=100
API_RATE_LIMIT_PER_MINUTE=30

# Database Pool Configuration
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=30
DB_POOL_PRE_PING=true
DB_POOL_RECYCLE=3600

# Celery Configuration
CELERY_BROKER_URL=redis://:password@localhost:6379/0
CELERY_RESULT_BACKEND=redis://:password@localhost:6379/0
CELERY_TASK_ALWAYS_EAGER=false
CELERY_WORKER_CONCURRENCY=4

# Monitoring and Logging
ENABLE_METRICS=true
METRICS_PORT=9090
LOG_FORMAT=json
LOG_FILE=logs/cti_scraper.log

# Content Processing
MAX_CONTENT_LENGTH=10485760  # 10MB
CONTENT_CLEANUP_ENABLED=true
GARBAGE_DETECTION_ENABLED=true

# Source Configuration
DEFAULT_CHECK_FREQUENCY=3600  # 1 hour
TIER1_CHECK_FREQUENCY=900     # 15 minutes
MAX_CONSECUTIVE_FAILURES=5
